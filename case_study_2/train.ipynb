{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 16:20:22.801703: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-17 16:20:22.801739: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 16:20:25.509108: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: UNKNOWN ERROR (100)\n",
      "2022-02-17 16:20:25.509164: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Lab): /proc/driver/nvidia/version does not exist\n",
      "2022-02-17 16:20:25.509355: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "x=np.loadtxt('geom.dat')\n",
    "y=np.loadtxt('TBE.dat')[:,np.newaxis]\n",
    "idx=np.random.permutation(len(x))\n",
    "ntrain=1000\n",
    "nvalidate=1000\n",
    "x_train=x[idx[:ntrain]]\n",
    "y_train=y[idx[:ntrain]]\n",
    "x_validate=x[idx[ntrain:ntrain+nvalidate]]\n",
    "y_validate=y[idx[ntrain:ntrain+nvalidate]]\n",
    "batch_size=4\n",
    "normalization=tf.keras.layers.Normalization(axis=None)\n",
    "normalization.adapt(x)\n",
    "training_set=tf.data.Dataset.from_tensor_slices((normalization(x_train), y_train)).shuffle(256).batch(batch_size)\n",
    "validation_set=tf.data.Dataset.from_tensor_slices((normalization(x_validate), y_validate)).shuffle(256).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1024\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 177765200.0000 - val_loss: 74428384.0000\n",
      "Epoch 2/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 72178904.0000 - val_loss: 75125552.0000\n",
      "Epoch 3/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71998184.0000 - val_loss: 74284192.0000\n",
      "Epoch 4/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71743648.0000 - val_loss: 74330352.0000\n",
      "Epoch 5/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71621968.0000 - val_loss: 75367888.0000\n",
      "Epoch 6/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71937288.0000 - val_loss: 73970416.0000\n",
      "Epoch 7/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71615280.0000 - val_loss: 73906896.0000\n",
      "Epoch 8/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71791976.0000 - val_loss: 74387400.0000\n",
      "Epoch 9/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71451824.0000 - val_loss: 75313848.0000\n",
      "Epoch 10/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71723392.0000 - val_loss: 74495304.0000\n",
      "Epoch 11/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71828872.0000 - val_loss: 74135112.0000\n",
      "Epoch 12/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71736208.0000 - val_loss: 75535856.0000\n",
      "Epoch 13/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71953360.0000 - val_loss: 74157296.0000\n",
      "Epoch 14/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71481640.0000 - val_loss: 73817176.0000\n",
      "Epoch 15/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71758672.0000 - val_loss: 74541880.0000\n",
      "Epoch 16/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71464096.0000 - val_loss: 73828952.0000\n",
      "Epoch 17/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71764232.0000 - val_loss: 74692952.0000\n",
      "Epoch 18/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71378664.0000 - val_loss: 73806488.0000\n",
      "Epoch 19/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 70813992.0000 - val_loss: 75270568.0000\n",
      "Epoch 20/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71400384.0000 - val_loss: 74362344.0000\n",
      "Epoch 21/1024\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71421088.0000 - val_loss: 74566112.0000\n",
      "Epoch 22/1024\n",
      "108/250 [===========>..................] - ETA: 0s - loss: 67142840.0000"
     ]
    }
   ],
   "source": [
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(y.shape[-1], activation='linear')\n",
    "])\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,loss='mse')\n",
    "csv_logger=tf.keras.callbacks.CSVLogger('training.log')\n",
    "history=model.fit(training_set, epochs=1024, verbose=1, validation_data=validation_set, callbacks=csv_logger)\n",
    "\n",
    "np.savetxt('result',np.concatenate((x,y,model(x).numpy()),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
